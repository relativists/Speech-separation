{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from AudioRNN.ckpt\n",
      "(189, 1026)\n",
      "播放结束！\n",
      "播放结束！\n"
     ]
    }
   ],
   "source": [
    "import wave  \n",
    "import struct\n",
    "import os\n",
    "from scipy import signal\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "# from tensorflow.python.ops import variable_scope as vs\n",
    "tf.reset_default_graph()\n",
    "\n",
    "path = r'C:\\Users\\xujiahao\\Desktop\\MIR-1K_for_MIREX\\trainwav' #文件夹目录 \n",
    "\n",
    "fname1 = 'left.wav'\n",
    "fname2 = 'right.wav'\n",
    "\n",
    "nframes = 96000\n",
    "framerate = 16000\n",
    "sampwidth = 2\n",
    "\n",
    "batch_size = 1\n",
    "num_steps = 189\n",
    "step_num = 513\n",
    "rnn_hidden1_size = 200 #它的大小可自己随便取,hidden1_size==step_num\n",
    "rnn_hidden2_size = 100\n",
    "rnn_hiddenL_size = 200\n",
    "state_size = 200 #等于rnn_hiddenL_size最后一个隐藏层的size\n",
    "y_size = step_num*2 #等于step_num的两倍\n",
    "soft=1e-4\n",
    "\n",
    "#生成音频文件\n",
    "def Generate_Wav(fname, wave_data, width, rate):\n",
    "    wf = wave.open(fname,'wb')\n",
    "    wf.setnchannels(1)\n",
    "    wf.setsampwidth(width)\n",
    "    wf.setframerate(rate)\n",
    "    for i in wave_data:\n",
    "        data = struct.pack('<h', int(i))\n",
    "        wf.writeframesraw( data )\n",
    "    wf.close()\n",
    "\n",
    "#对读入文件预处理\n",
    "def init_handle(filename):\n",
    "    f = wave.open(filename)\n",
    "    params = f.getparams()  #读取格式信息\n",
    "    #一次性返回所有的WAV文件的格式信息，它返回的是一个组元(tuple)：声道数, 量化位数（byte单位）, 采  \n",
    "    #样频率, 采样点数, 压缩类型, 压缩类型的描述。wave模块只支持非压缩的数据，因此可以忽略最后两个信息\n",
    "    nframes1 = params[3]\n",
    "    #读取声音数据，传递一个参数指定需要读取的长度（以取样点为单位）\n",
    "    str_buf  = f.readframes(nframes1)\n",
    "    f.close()\n",
    "    str_data = np.frombuffer(str_buf,dtype = np.short)\n",
    "    #将wave_data数组改为2列，行数自动匹配。在修改shape的属性时，需使得数组的总长度不变。\n",
    "    str_data.shape = -1,2\n",
    "    str_data = str_data.T   #转置数据,第一行为为左声道（配乐），第二行为右声道（人声）\n",
    "    if(len(str_data[0]) >= nframes):#变为单声道采样点为96000（时长6秒）\n",
    "        wave_left = str_data[0, :nframes]\n",
    "        wave_right = str_data[1, :nframes]\n",
    "    if(len(str_data[0]) < nframes):\n",
    "        concat = np.zeros(nframes-len(str_data[0]))\n",
    "        wave_left = np.append(str_data[0], concat)\n",
    "        wave_right = np.append(str_data[1], concat)\n",
    "    #短时傅里叶变换    \n",
    "    f, t, Z_left1 = signal.stft(wave_left, fs = framerate, nperseg = 1024, noverlap = 512)\n",
    "    f, t, Z_right1 = signal.stft(wave_right, fs = framerate, nperseg = 1024, noverlap = 512)\n",
    "    theta = np.angle(Z_left1 + Z_right1)  #求混合语音傅里叶变换后的相位谱\n",
    "    Z_left = Z_left1.T\n",
    "    Z_right = Z_right1.T\n",
    "    left = abs(Z_left)  #音乐声幅度谱\n",
    "    right = abs(Z_right)  #人声幅度谱\n",
    "    y1 = (left+0.1)/(left + right + 0.1)  #labelY\n",
    "    y2 = (right+0.1)/(left + right +0.1)\n",
    "    X = abs(Z_left+Z_right) #混合语音幅度谱\n",
    "    #X = np.reshape(X,(1, num_steps, step_num))\n",
    "    Y = np.column_stack((y1,y2))\n",
    "    return theta, X, Y\n",
    "\n",
    "#对预测数据进行处理\n",
    "def out_handle(theta, X, prediction):\n",
    "    X = X.T\n",
    "    prediction = prediction.T\n",
    "    y1 = prediction[:step_num, :]\n",
    "    y2 = prediction[step_num:, :]\n",
    "    s1 = (y1+soft)/(y1 + y2 + soft)  #软时频掩模\n",
    "    s2 = (y2+soft)/(y1 + y2 + soft)\n",
    "    X_left = X * s1   #左声道（音乐声）的幅度谱\n",
    "    X_right = X * s2\n",
    "    Z_left = X_left*np.cos(theta) + 1j*X_left*np.sin(theta)\n",
    "    Z_right = X_right*np.cos(theta) + 1j*X_right*np.sin(theta)\n",
    "    _, data_left = signal.istft(Z_left, framerate, nperseg = 1024, noverlap = 512)\n",
    "    _, data_right = signal.istft(Z_right, framerate, nperseg = 1024, noverlap = 512)\n",
    "    Generate_Wav(fname1, data_left, sampwidth, framerate)\n",
    "    Generate_Wav(fname2, data_right, sampwidth, framerate)\n",
    "\n",
    "class AudioRNN:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.x1 = tf.placeholder(tf.float32, [num_steps, step_num], name='input_placeholder')\n",
    "        self.x = tf.reshape(self.x1, [batch_size, num_steps, step_num])\n",
    "        self.y = tf.placeholder(tf.float32, [num_steps,y_size], name='output_placeholder')\n",
    "        self.lr = tf.Variable(0.01,dtype=tf.float32)\n",
    "        \n",
    "    def RNNLayer(self):\n",
    "        rnn_layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=size, reuse=tf.AUTO_REUSE) for size in [rnn_hidden1_size, rnn_hidden2_size, rnn_hiddenL_size]]\n",
    "        rnn_multi = tf.contrib.rnn.MultiRNNCell(rnn_layers)\n",
    "        initial_state = rnn_multi.zero_state(batch_size, dtype=tf.float32)\n",
    "        #with tf.variable_scope(\"scope\", reuse=None):\n",
    "        outputs, last_states = tf.nn.dynamic_rnn(cell=rnn_multi,inputs=self.x, initial_state=initial_state, dtype=tf.float32)\n",
    "        outputs = tf.reshape(outputs, [-1, state_size])\n",
    "        \n",
    "        with tf.variable_scope(\"sigmoid1\", reuse=tf.AUTO_REUSE):\n",
    "            W1 = tf.get_variable('W', [state_size, y_size])#随机生成范围在正态分布标准差为0.1的w\n",
    "            b1 = tf.get_variable('b', [y_size], initializer=tf.constant_initializer(0.0))\n",
    "        #logits1 = tf.reshape(tf.matmul(outputs, W) + b,[num_steps,y_size])\n",
    "        logits = tf.matmul(outputs, W1) + b1\n",
    "        predictions = tf.nn.sigmoid(logits)\n",
    "        return logits, predictions\n",
    "    \n",
    "    #创建RNN网络会话框并训练\n",
    "    def train(self, tf_save_path):\n",
    "        epoch = 3\n",
    "        \n",
    "        logits,_ = self.RNNLayer()\n",
    "        \n",
    "        losses = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=self.y)\n",
    "        total_loss = tf.reduce_mean(losses)\n",
    "        train_step = tf.train.AdadeltaOptimizer(self.lr).minimize(total_loss)#优化器和最小化损失，就是损失函数对参数的计算\n",
    "        #print(losses,total_loss,train_step)\n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())#初始化变量\n",
    "            #训练\n",
    "            for i in range(epoch):\n",
    "                sess.run(tf.assign(self.lr,0.5)) #可以调整每次训练的学习率，例如0.5*（0.9 ** i）\n",
    "                for filename in os.listdir(path):\n",
    "                    filename = path+\"/\"+filename\n",
    "                    _, train_X, train_Y = init_handle(filename)\n",
    "    #                 train_X1 = np.reshape(train_X,(batch_size, num_steps, step_num)) #变成rnn可接受的三维矩阵\n",
    "                    to, _ = sess.run([total_loss,train_step],feed_dict={self.x1:train_X, self.y:train_Y})\n",
    "#                 if(i%10==0):\n",
    "                print(\"step\"+str(i)+\"\\t\"+\"loss:\",to)\n",
    "\n",
    "            save_path = saver.save(sess, tf_save_path)\n",
    "#             writer = tf.summary.FileWriter(\"./summary\", tf.get_default_graph())\n",
    "#             writer.close()\n",
    "            print(\"Model saved in file: %s\" %save_path)\n",
    "#             sess.close()\n",
    "\n",
    "    def test(self, testfile, tfsavepath):\n",
    "#         vs.get_variable_scope().reuse_variables()\n",
    "        _, predictions = self.RNNLayer()\n",
    "       \n",
    "        test_theta, test_X, _ = init_handle(testfile)\n",
    "        saver = tf.train.Saver()\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            saver.restore(sess, tfsavepath)\n",
    "            prediction = sess.run(predictions,feed_dict={self.x1:test_X})\n",
    "            out_handle(test_theta, test_X, prediction)\n",
    "            print(prediction.shape)\n",
    "\n",
    "import pyaudio\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "class Control:\n",
    "    def __init__(self, RNN, savepath, testfile):\n",
    "        self.RNN = RNN\n",
    "        self.savepath = savepath\n",
    "        self.testfile = testfile\n",
    "        self.root = tk.Tk()  \n",
    "        self.root.title(\"控制面板\")  # 给主窗口设置标题内容\n",
    "        self.root.geometry('500x352')\n",
    "        self.canvas = tk.Canvas(self.root, height=352, width=500)#创建画布      \n",
    "        self.imgpath = 'kehuan.jpg'\n",
    "        self.img = Image.open(self.imgpath)\n",
    "        self.image_file = ImageTk.PhotoImage(self.img)#加载图片文件\n",
    "        self.canvas.create_image(0,0, anchor='nw', image=self.image_file)#将图片置于画布上  \n",
    "        self.canvas.pack(side='top')\n",
    "        \n",
    "        self.trainBtn = tk.Button(self.canvas, command = self.TrainBtn, text = \"开始训练\")\n",
    "        self.getfileBtn = tk.Button(self.canvas, command = self.SelectFile, text = \"选择音频文件\")\n",
    "        self.separateBtn = tk.Button(self.canvas, command = self.SeparateBtn, text = \"开始分离\")\n",
    "        self.leftBtn = tk.Button(self.canvas, command = self.LeftBtn, text = \"播放背景音乐\")\n",
    "        self.rightBtn = tk.Button(self.canvas, command = self.RightBtn, text = \"播放人声\")\n",
    "\n",
    "#         self.p = tk.StringVar()\n",
    "#         self.p.set(\"播放提示！\")\n",
    "        self.trainlabel = tk.Label(self.canvas)\n",
    "        self.text = tk.Text(self.canvas)#显示音频文件\n",
    "        self.separatelabel = tk.Label(self.canvas, text=\"请先确认分离默认音频或已经选好的！\", foreground=\"red\")\n",
    "        self.playlabel = tk.Label(self.canvas, text=\"播放提示！\", foreground=\"red\")\n",
    "\n",
    "    def gui_arrang(self):\n",
    "        self.canvas.create_window(100, 50, width=80, height=30,window=self.trainBtn)\n",
    "        self.canvas.create_window(100, 130, width=80, height=30,window=self.getfileBtn)\n",
    "        self.canvas.create_window(100, 210, width=80, height=30,window=self.separateBtn)\n",
    "        self.canvas.create_window(150, 290, width=80, height=30,window=self.leftBtn)\n",
    "        self.canvas.create_window(350, 290, width=80, height=30,window=self.rightBtn)\n",
    "\n",
    "        self.canvas.create_window(300, 50, width=300, height=30, window=self.trainlabel)\n",
    "        self.canvas.create_window(300, 130, width=300, height=30, window=self.text)\n",
    "        self.canvas.create_window(300, 210, width=300, height=30, window=self.separatelabel)\n",
    "        self.canvas.create_window(250, 300, width=80, height=30, window=self.playlabel)\n",
    "\n",
    "        if os.path.exists(self.savepath + '.meta'):\n",
    "            self.trainlabel.config(text=\"已有模型，可直接分离！\", foreground=\"red\")\n",
    "        else:\n",
    "            self.trainlabel.config(text=\"请先训练模型！\", foreground=\"red\")\n",
    "            \n",
    "        self.text.tag_config(\"tag1\", foreground=\"red\", offset=-7)\n",
    "        self.text.insert(tk.INSERT, self.testfile, \"tag1\")\n",
    "        self.text.config(state=tk.DISABLED)\n",
    "        self.root.mainloop()\n",
    "        \n",
    "    def TrainBtn(self):\n",
    "        self.trainlabel.config(text=\"正在训练，请稍等！\", foreground=\"red\")\n",
    "        self.RNN.train(self.savepath)\n",
    "        self.trainlabel.config(text=\"完成训练！\", foreground=\"red\")\n",
    "\n",
    "    def SelectFile(self):\n",
    "        self.testfile = tk.filedialog.askopenfilename()\n",
    "        self.text.tag_config(\"tag1\", foreground=\"red\")\n",
    "        if self.testfile != '':\n",
    "            self.text.config(state=tk.NORMAL)\n",
    "            self.text.delete(1.0, tk.END)\n",
    "            self.text.insert(tk.INSERT, self.testfile, \"tag1\")\n",
    "            self.text.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            self.text.config(state=tk.NORMAL)\n",
    "            self.text.delete(1.0, tk.END)\n",
    "            self.text.insert(tk.INSERT, \"您未选择文件！\", \"tag1\")\n",
    "            self.text.config(state=tk.DISABLED)\n",
    "            \n",
    "    def SeparateBtn(self):\n",
    "        self.separatelabel.config(text=\"正在分离，请稍等！\", foreground=\"red\")\n",
    "        self.RNN.test(self.testfile, self.savepath)\n",
    "        self.separatelabel.config(text=\"完成分离！\", foreground=\"red\")\n",
    "        \n",
    "    def LeftBtn(self):\n",
    "        self.playlabel.config(text=\"正在播放！\", foreground=\"red\")\n",
    "        filename = 'left.wav'\n",
    "        self.PlayMusic(filename)\n",
    "        \n",
    "    def RightBtn(self):\n",
    "        filename = 'right.wav'\n",
    "        self.PlayMusic(filename)\n",
    "        \n",
    "    def PlayMusic(self, filename):\n",
    "        self.playlabel.config(text=\"正在播放！\", foreground=\"red\")\n",
    "        wf = wave.open(filename,'rb')\n",
    "        pms = wf.getparams()\n",
    "        nchannels1, sampwidth1, framerate1, nframes1 = pms[:4]\n",
    "        p = pyaudio.PyAudio() \n",
    "        stream=p.open(format = p.get_format_from_width(sampwidth1), channels = nchannels1, rate = framerate1, output = True)\n",
    "        data=wf.readframes(nframes1)\n",
    "        stream.write(data)\n",
    "        stream.stop_stream()   # 停止数据流\n",
    "        stream.close()\n",
    "        p.terminate()  # 关闭 PyAudio\n",
    "        self.playlabel.config(text=\"播放结束！\", foreground=\"red\")\n",
    "        print(\"播放结束！\")\n",
    "            \n",
    "def main(_):\n",
    "    savepath = 'AudioRNN.ckpt'\n",
    "    testfile = r'C:\\Users\\xujiahao\\Desktop\\MIR-1K_for_MIREX\\Wavfile\\amy_7_03.wav'\n",
    "    RNN = AudioRNN()\n",
    "    C = Control(RNN, savepath, testfile)\n",
    "    C.gui_arrang()\n",
    "\n",
    "#     RNN.train(savepath)\n",
    "#     RNN.test(testfile, savepath)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from PIL import ImageTk, Image\n",
    "from tkinter import filedialog\n",
    "import wave\n",
    "import pyaudio\n",
    "import pygame\n",
    "\n",
    "# path = r'C:\\Users\\xujiahao\\Desktop\\MIR-1K_for_MIREX\\trainwav' #文件夹目录 \n",
    "# print(len(os.listdir(path)))\n",
    "\n",
    "class Control:\n",
    "    def __init__(self, RNN, savepath, testfile):\n",
    "        self.RNN = RNN\n",
    "        self.savepath = savepath\n",
    "        self.testfile = testfile\n",
    "        self.root = tk.Tk()  \n",
    "        self.root.title(\"控制面板\")  # 给主窗口设置标题内容\n",
    "        self.root.geometry('500x352')\n",
    "        self.canvas = tk.Canvas(self.root, height=352, width=500)#创建画布      \n",
    "        self.imgpath = 'kehuan.jpg'\n",
    "        self.img = Image.open(self.imgpath)\n",
    "        self.image_file = ImageTk.PhotoImage(self.img)#加载图片文件\n",
    "        self.canvas.create_image(0,0, anchor='nw', image=self.image_file)#将图片置于画布上  \n",
    "        self.canvas.pack(side='top')\n",
    "        \n",
    "        self.trainBtn = tk.Button(self.canvas, command = self.TrainBtn, text = \"开始训练\")\n",
    "        self.getfileBtn = tk.Button(self.canvas, command = self.SelectFile, text = \"选择语频文件\")\n",
    "        self.testBtn = tk.Button(self.canvas, command = self.TestBtn, text = \"开始分离\")\n",
    "        self.leftBtn = tk.Button(self.canvas, command = self.LeftBtn, text = \"播放背景音乐\")\n",
    "        self.rightBtn = tk.Button(self.canvas, command = self.RightBtn, text = \"播放人声\")\n",
    "\n",
    "        self.label = tk.Label(self.canvas)\n",
    "        self.text = tk.Text(self.canvas)\n",
    "\n",
    "    def gui_arrang(self):\n",
    "        self.canvas.create_window(100, 50, width=80, height=30,window=self.trainBtn)\n",
    "        self.canvas.create_window(100, 130, width=80, height=30,window=self.getfileBtn)\n",
    "        self.canvas.create_window(100, 210, width=80, height=30,window=self.testBtn)\n",
    "        self.canvas.create_window(150, 290, width=80, height=30,window=self.leftBtn)\n",
    "        self.canvas.create_window(350, 290, width=80, height=30,window=self.rightBtn)\n",
    "\n",
    "        self.canvas.create_window(300, 50, width=300, height=30, window=self.label)\n",
    "        self.canvas.create_window(300, 130, width=300, height=30, window=self.text)\n",
    "\n",
    "        self.text.tag_config(\"tag1\", foreground=\"red\", offset=-7)\n",
    "        self.text.insert(tk.INSERT, self.testfile, \"tag1\")\n",
    "        self.text.config(state=tk.DISABLED)\n",
    "        self.root.mainloop()\n",
    "        \n",
    "    def TrainBtn(self):\n",
    "        print(self.RNN)\n",
    "\n",
    "    def SelectFile(self):\n",
    "        self.testfile = tk.filedialog.askopenfilename()\n",
    "        self.text.tag_config(\"tag1\", foreground=\"red\")\n",
    "        if self.testfile != '':\n",
    "            self.text.config(state=tk.NORMAL)\n",
    "            self.text.delete(1.0, tk.END)\n",
    "            self.text.insert(tk.INSERT, self.testfile, \"tag1\")\n",
    "            self.text.config(state=tk.DISABLED)\n",
    "        else:\n",
    "            self.text.config(state=tk.NORMAL)\n",
    "            self.text.delete(1.0, tk.END)\n",
    "            self.text.insert(tk.INSERT, \"您未选择文件\", \"tag1\")\n",
    "            self.text.config(state=tk.DISABLED)\n",
    "            \n",
    "    def TestBtn(self):\n",
    "        print(self.savepath)\n",
    "        \n",
    "    def LeftBtn(self):\n",
    "        fname1 = 'left.wav'\n",
    "        self.PlayMusic(fname1)\n",
    "        print(1)\n",
    "        \n",
    "    def RightBtn(self):\n",
    "        fname2 = 'right.wav'\n",
    "        self.PlayMusic(fname2)\n",
    "        print(2)\n",
    "        \n",
    "    def PlayMusic(self, filename):\n",
    "        wf = wave.open(filename,'rb')\n",
    "        pms = wf.getparams()\n",
    "        nchannels1, sampwidth1, framerate1, nframes1 = pms[:4]\n",
    "        p = pyaudio.PyAudio() \n",
    "        stream=p.open(format = p.get_format_from_width(sampwidth1), channels = nchannels1, rate = framerate1, output = True)\n",
    "#         while True:\n",
    "        data=wf.readframes(nframes1)\n",
    "#             if data==\"\":\n",
    "#                 break\n",
    "        stream.write(data)\n",
    "        stream.stop_stream()   # 停止数据流\n",
    "        stream.close()\n",
    "        p.terminate()  # 关闭 PyAudio\n",
    "        print(\"播放结束！\")\n",
    "        \n",
    "#     def PlayMusic(self, filename, loops=0, start=0.0, value=0.5):\n",
    "#         flag = True\n",
    "#         pygame.mixer.init()  # 音乐模块初始化\n",
    "#         track = pygame.mixer.music.load(filename)\n",
    "#         pygame.mixer.music.play()\n",
    "#         pygame.mixer.music.set_volume(value)  # 来设置播放的音量，音量value的范围为0.0到1.0。\n",
    "#         pygame.mixer.music.play(loops=loops, start=start)  #loops和start分别代表重复的次数和开始播放的位置。\n",
    "# #         pygame.mixer.music.stop()  # 停止播放\n",
    "# #         music = pygame.mixer.Sound(filename)\n",
    "# #         music.play()\n",
    "# #         music.stop()\n",
    "\n",
    "C = Control(1,2,\"wer\")\n",
    "C.gui_arrang()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
